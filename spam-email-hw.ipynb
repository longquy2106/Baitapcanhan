{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\ndata = pd.read_csv('../input/data-spam/spam_email.txt',sep=' ')\nsp_data=data.loc[:,'make':'cap_total']\nsp_data.describe(include='all')","metadata":{"execution":{"iopub.status.busy":"2022-04-08T02:56:40.90654Z","iopub.execute_input":"2022-04-08T02:56:40.907251Z","iopub.status.idle":"2022-04-08T02:56:41.07324Z","shell.execute_reply.started":"2022-04-08T02:56:40.907203Z","shell.execute_reply":"2022-04-08T02:56:41.072542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\nX=sp_data.values\nyCh=data.values[:,57]\ny=np.zeros((yCh.size))\ny[yCh=='ham']=1\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 0)\nstd_scaler = preprocessing.StandardScaler().fit(X_train)\nX_train_scaled = std_scaler.transform(X_train)\nX_test_scaled = std_scaler.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T03:01:25.884751Z","iopub.execute_input":"2022-04-08T03:01:25.885516Z","iopub.status.idle":"2022-04-08T03:01:25.919623Z","shell.execute_reply.started":"2022-04-08T03:01:25.88547Z","shell.execute_reply":"2022-04-08T03:01:25.918903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\npca= PCA(n_components=2)\nfig, (plt_train, plt_test) = plt.subplots(1, 2)\ndata1=pca.fit_transform(X_train_scaled)\nh1=data1[(y_train==1)]\nh2=data1[(y_train==0)]\nplt_train.set_title('Train values :'+ str(X_train_scaled.shape))\nplt_train.scatter(h1[:,0],h1[:,1],marker='*',c=\"red\")\nplt_train.scatter(h2[:,0],h2[:,1],marker='+',c=\"black\")\nplt_train.legend(['label 1','label 0'])\ndata2=pca.fit_transform(X_test_scaled)\ng1=data2[(y_test==1)]\ng2=data2[(y_test==0)]\nplt_test.set_title('Test values :'+str(X_test_scaled.shape))\nplt_test.scatter(g1[:,0],g1[:,1],marker='+',c=\"black\")\nplt_test.scatter(g2[:,0],g2[:,1],marker='*',c=\"pink\")\nplt_test.legend(['label 1','label 0'])","metadata":{"execution":{"iopub.status.busy":"2022-04-08T03:01:38.771631Z","iopub.execute_input":"2022-04-08T03:01:38.772491Z","iopub.status.idle":"2022-04-08T03:01:39.362003Z","shell.execute_reply.started":"2022-04-08T03:01:38.772432Z","shell.execute_reply":"2022-04-08T03:01:39.361218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.decomposition import PCA\nimport matplotlib.pyplot as plt\npca= PCA(n_components=2)\n\nX_scaled = std_scaler.transform(X)\ndatax=pca.fit_transform(X_scaled)\nx1=datax[(y==1)]\nx2=datax[(y==0)]\nplt.title('Train values :'+ str(X.shape))\nplt.scatter(x1[:,0],x1[:,1],marker='*',c=\"orange\")\nplt.scatter(x2[:,0],x2[:,1],marker='+',c=\"black\")\nplt.legend(['lable 1','lable 0'])","metadata":{"execution":{"iopub.status.busy":"2022-04-08T02:56:53.348822Z","iopub.execute_input":"2022-04-08T02:56:53.349379Z","iopub.status.idle":"2022-04-08T02:56:53.723421Z","shell.execute_reply.started":"2022-04-08T02:56:53.34934Z","shell.execute_reply":"2022-04-08T02:56:53.722522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RatingModel:\n    def __init__(self, y_1, y_2):\n      self.y_1=y_1\n      self.y_2=y_2\n      self.TN=np.size(y_2[(y_2==-1)&(y_1==y_2)])\n      self.FN=np.size(y_2[(y_2==-1)&(y_1!=y_2)])\n      self.TP=np.size(y_2[(y_2==1)&(y_1==y_2)])\n      self.FP=np.size(y_2[(y_2==1)&(y_1!=y_2)])\n      self.y_1[self.y_1==0]=-1\n      self.y_2[self.y_2==0]=-1\n     \n    def _rep():\n        return \"\"\n    def accur_Error(self, y_1, y_2):\n        rs=(self.TP+self.TN)/(y_1.size)\n        return [rs,(1-rs)]\n    def sensitivity(self):\n        P=np.size(self.y_1[self.y_1==1])\n        return (self.TP)/(P)\n    def specificity(self):\n        N=np.size(self.y_1[self.y_1==-1])\n        return (self.TN)/(N)\n    def precision(self):\n        rs=self.TP+self.FP\n        return (self.TP)/(rs)\n    def recall(self):\n        rs=self.TP+self.FN\n        return (self.TP)/(rs)\n    def rating(self):\n        return [self.accur_Error(self.y_1, self.y_2), self.sensitivity(), self.specificity(), self.precision(), self.recall()]\nclass DecisionStump:\n    def __init__(self, T=100): #\n        self.T = T\n        pass\n\n    def fit(self, X: np.ndarray, y: np.ndarray, sample_weight: np.ndarray):\n        T = self.T\n        W=sample_weight\n        nrow, ncol = X.shape\n        assert nrow == y.size\n\n        bestn = 0\n        bestd = 1\n        bestp = 0\n        minerr = W.sum()\n        for i in range(ncol):\n            err, d, p = self._optimize(X[:, i], y, W, T)\n            if err < minerr:\n                minerr = err\n                bestn = i\n                bestd = d\n                bestp = p\n        \n        self.features = ncol\n        self.bestn = bestn\n        self.bestd = bestd\n        self.bestp = bestp\n\n        return self\n\n    def _optimize(self, X, y, W, T):\n        X = X.flatten()\n        min_x, max_x = X.min(), X.max()\n        len_x = max_x - min_x\n        \n        bestd = 1\n        bestp = min_x\n        minerr = W.sum()\n\n        if len_x > 0.0:\n            for p in np.arange(min_x, max_x, len_x/T):\n                for d in [-1, 1]:\n                    gy = np.ones((y.size))\n                    gy[X*d < p*d] = -1\n                    err = np.sum((gy != y)*W)\n                    if err < minerr:\n                        minerr = err\n                        bestd = d\n                        bestp = p\n\n        return minerr, bestd, bestp\n\n    def predict(self, test_set : np.ndarray):\n        nrow, ncol = test_set.shape\n\n        assert ncol == self.features\n\n        icol = test_set[:, self.bestn]\n        h = np.ones((nrow))\n        h[icol*self.bestd < self.bestp*self.bestd] = -1\n        return h\nclass AdaBoost:\n    def __init__(self , T, hmodel = DecisionStump()):\n        self.T=T\n        self.hmodel=hmodel\n    def fit(self, X: np.ndarray, y_1: np.ndarray, verbose=False):\n      n = X.shape[0]\n      T = self.T\n      y=y_1\n      y[y==0]=-1\n    # init numpy arrays\n      self.D = np.zeros(shape=(T, n))\n      self.h = np.zeros(shape=T, dtype=object)\n      self.alpha = np.zeros(shape=T)\n      self.errors = np.zeros(shape=T)\n      self.ratting = np.zeros(shape=(T,2))\n\n      # initialize weights uniformly\n      self.D[0] = np.ones(shape=n) / n\n\n      for t in range(T):\n          # fit  weak learner\n          D_ = self.D[t]\n          h_ = DecisionStump(40)\n          h_ = h_.fit(X, y, D_)\n\n          # calculate error and stump weight from weak learner prediction\n          Pr_ = h_.predict(X)\n          error_ = D_[(Pr_ != y)].sum()# / n\n          alpha_ = np.log((1 - error_) / error_) / 2\n\n          # update sample weights\n          D_new = (\n              D_ * np.exp(-alpha_ * y * Pr_)\n          )\n          \n          D_new /= D_new.sum()\n\n          # If not final iteration, update sample weights for t+1\n          if t+1 < T:\n              self.D[t+1] = D_new\n\n          # save results of iteration\n          self.h[t] = h_\n          self.alpha[t] = alpha_\n          self.errors[t] = error_\n          # ae=np.array([0,0])\n          if t>0:\n            Pr_temp=self.predictmodul(X,t)\n            modelra=RatingModel(y, Pr_temp)\n            self.ratting[t,:]=modelra.accur_Error(y, Pr_temp)\n          if verbose: print('Time {0}-th weak: accuracy={1}, error={2}'.format (t, self.ratting[t,0], self.ratting[t,1]))\n      return self\n    def predict(self, X):\n        Pr_ = np.array([h_.predict(X) for h_ in self.h])\n        return np.sign(np.dot(self.alpha, Pr_))\n    def predictmodul(self, X, i):\n        h_temp=self.h[:i]\n        alpha_temp=self.alpha[:i]\n        Pr_ = np.array([h_.predict(X) for h_ in h_temp])\n        return np.sign(np.dot(alpha_temp, Pr_))","metadata":{"execution":{"iopub.status.busy":"2022-04-08T02:56:56.003523Z","iopub.execute_input":"2022-04-08T02:56:56.004102Z","iopub.status.idle":"2022-04-08T02:56:56.041665Z","shell.execute_reply.started":"2022-04-08T02:56:56.004054Z","shell.execute_reply":"2022-04-08T02:56:56.040661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=AdaBoost(40)\nmodel=model.fit(X_train_scaled, y_train,  True )\nPr=model.predict( X_test_scaled)\nPr[(Pr==0)]=-1\nprint(Pr, y_test)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T02:57:01.783038Z","iopub.execute_input":"2022-04-08T02:57:01.783381Z","iopub.status.idle":"2022-04-08T02:57:10.423931Z","shell.execute_reply.started":"2022-04-08T02:57:01.783344Z","shell.execute_reply":"2022-04-08T02:57:10.422756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ra_Xtest = np.zeros(shape=(model.T,2))\nfor i in range(1,model.T):\n  Pr_i=model.predictmodul(X_test_scaled,i)\n  modelra=RatingModel(y_test, Pr_i)\n  ra_Xtest[i,:]=modelra.accur_Error(y_test, Pr_i)\nra_Xtrain = np.zeros(shape=(model.T,2))\nfor i in range(1,model.T):\n  Pr_i=model.predictmodul(X_train_scaled,i)\n  modelra=RatingModel(y_train, Pr_i)\n  ra_Xtrain[i,:]=modelra.accur_Error(y_train, Pr_i)\niter=range(model.T)\nplt.plot(iter,ra_Xtest[:,0],'y-', label='Kiểm tra độ chính xác')\nplt.plot(iter,ra_Xtest[:,1],'r-', label='Kiểm tra lỗi')\nplt.plot(iter,ra_Xtrain[:,0],'y--', label='Huấn luyện độ chính xác')\nplt.plot(iter,ra_Xtrain[:,1],'r--', label='Huấn luyện lỗi')\nplt.legend(loc='center right')\nplt.xlabel('Lần lặp')\nplt.ylabel('Mất / Chính xác')","metadata":{"execution":{"iopub.status.busy":"2022-04-08T02:57:53.884409Z","iopub.execute_input":"2022-04-08T02:57:53.885285Z","iopub.status.idle":"2022-04-08T02:57:54.27476Z","shell.execute_reply.started":"2022-04-08T02:57:53.885222Z","shell.execute_reply":"2022-04-08T02:57:54.274095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sumerror=0;\ny_new=y_test\ny_new[y_new==0]=-1\nfor i in range(y_new.shape[0]):\n  if y_new[i]!=Pr[i]: \n    sumerror+=1\nprint(sumerror, y_new.shape)\ngT1=data2[(Pr==1)]\ngT0=data2[(Pr==-1)]\ngF1=data2[(y_new!=Pr)&(Pr==1)]\ngF0=data2[(y_new!=Pr)&(Pr==-1)]\nplt.title('Test values errors :'+str(sumerror)+'/ '+str(X_test_scaled.shape[0]))\n\nplt.scatter(gT1[:,0],gT1[:,1], marker='*', c='red')\nplt.scatter(gT0[:,0],gT0[:,1], marker='x', c='black')\nplt.scatter(gF1[:,0],gF1[:,1], marker='s', c='pink')\nplt.scatter(gF0[:,0],gF0[:,1], marker='+',c='green')\nplt.legend(['TP spam','TN ham','FP spam','FN ham'])","metadata":{"execution":{"iopub.status.busy":"2022-04-08T02:59:28.291498Z","iopub.execute_input":"2022-04-08T02:59:28.291775Z","iopub.status.idle":"2022-04-08T02:59:28.686021Z","shell.execute_reply.started":"2022-04-08T02:59:28.291747Z","shell.execute_reply":"2022-04-08T02:59:28.68521Z"},"trusted":true},"execution_count":null,"outputs":[]}]}